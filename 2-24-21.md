### February 24th, 2021 | Lecture 6
vaishnavi - hand motion
do not track wrinkles, creases, bulges. this paper tracks self contact + occlusion
that is interesting. I had never thought about tracking the object details of the hand.
3D scan a surface mesh, create volumetric tetrahedral mesh -> used to represent deformable body and make sure morphing makes sense
motion sequences deform this original mesh

minimize energy equation at each frame
	vision, physics/elasticity, linking
the collisions between the contours and the hands looks really believable and theres no clipping or strange deformations of the flesh
i hadnt really realied that hands are very fleshy and soft actually
agree that it could be further optimized for speed but it does have to keep track of many physics variables along the mesh to create realistic defomration
deforms previous frames mesh so prone to drift

anna stop motion face anim
i liked the animation in kubo and the 3 strings so this is very interesting to see how they produce them
and it would definitely be good to optimize the expense of creating 3d models for stop motion
generates different libraries for top and bottom of face which is interesting how they apply deformation between these parts
impressive how many frames captured with just 2 libraries
makes sense that number of frames doesnt scale linearly, to increase number of frames need fewer addl libraries because its a combination between the different libraries, and need the basic set of expressions to span basic expressions
facial animation looks really good and believable, so this is good esp bc facial animation needs to be expressive and its easy to notice errors

nikolas
pinocchio easily rig and animate mesh
step 1. approximate medial surface - interior points where equidistant to surface of mesh
step 2. make packed spheres from last step
step 3. make graph of armature
step 4. embed, and then make it more regular looking
step 5. bind mesh to armature by heat diffusion method

nathan
motion synthesis for social conversations
nice to see a paper from cmu
create realistic dyadic (two individuals) conversations
divide into sentence/a point made, listener response/brief response, hesitation
i think these are good indicators and most speech can be divided into these categories
how do they determine what kind of hand motion to make, must create variation in hand motion or we reach uncanny valley
easy to see correlation between peaks in audio and peaks in movement
do they associate kinds of movements with the audio emotion
yeah noticed that many of the matched motions, while there was more motion during the emphasized parts or when people were speaking, and the motions themselves looked realistic, it didnt really match the emotion being expressed
am wondering if it could be combined with existing research on audio and emotion and label what kinds of motions are what kinds of emotion

alan
skeleton aware motion retargeting
motion retargeting - convert one skeletons motion to another skeleton while maintaining same motion
current methods not good enough, doing manually also time consuming
convert motion from complex skeleton to primal skeleton, then transfer to another skeleton
results seem quite good, cool that can add to chars with different number of joints and bones and uneven skeleton

